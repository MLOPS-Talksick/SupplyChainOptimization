{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5f2f0b60ad6e4390824a5de1d711a1a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8ef1bd53b64418fbc608be7cdb69ab7",
              "IPY_MODEL_166915f6a5f44ab2be6895a7db4c213c",
              "IPY_MODEL_e8dc03ba59bb44348fb4006e8fd05690"
            ],
            "layout": "IPY_MODEL_5090ffb6d9b9444a96a13c1ff2c28d39"
          }
        },
        "d8ef1bd53b64418fbc608be7cdb69ab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_804bf3ed5ba644c09821bc777b841177",
            "placeholder": "​",
            "style": "IPY_MODEL_1cce153c421c4348b986ab43daec9288",
            "value": "Downloading artifacts: 100%"
          }
        },
        "166915f6a5f44ab2be6895a7db4c213c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec24827ee60e4e469ab54e18eb59a8ef",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f9782c73d284ee1a9e6b74c33d2cabd",
            "value": 1
          }
        },
        "e8dc03ba59bb44348fb4006e8fd05690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ee49c86ec794f1296016e5d3a712765",
            "placeholder": "​",
            "style": "IPY_MODEL_3420a02b032a41e9a137b344f7a54421",
            "value": " 1/1 [00:00&lt;00:00, 99.79it/s]"
          }
        },
        "5090ffb6d9b9444a96a13c1ff2c28d39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "804bf3ed5ba644c09821bc777b841177": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cce153c421c4348b986ab43daec9288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec24827ee60e4e469ab54e18eb59a8ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f9782c73d284ee1a9e6b74c33d2cabd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ee49c86ec794f1296016e5d3a712765": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3420a02b032a41e9a137b344f7a54421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb3fe9f606794b9bba1317978f565613": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0d099a5ac5a4982ba909ab6650fa1cc",
              "IPY_MODEL_8d00ec2573794614808411ed4522b983",
              "IPY_MODEL_096ba20fca974672b7c11008cdc2f1a0"
            ],
            "layout": "IPY_MODEL_9c3f387d895f4b06894b844a837dcb08"
          }
        },
        "e0d099a5ac5a4982ba909ab6650fa1cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_008cded9607d4dc797e01ad2f7ad5e95",
            "placeholder": "​",
            "style": "IPY_MODEL_8c4b402ae27d49bca141c34cd738d1f7",
            "value": "Processing products: 100%"
          }
        },
        "8d00ec2573794614808411ed4522b983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0be482d975fa4cca92af125f7a6c441e",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8bbe349b1e84923a6ab71c57c702f39",
            "value": 8
          }
        },
        "096ba20fca974672b7c11008cdc2f1a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b174347bf9fc40d89bc07bbcd7d86864",
            "placeholder": "​",
            "style": "IPY_MODEL_c5de433240de4f7d9f79c62c3ddd644e",
            "value": " 8/8 [00:04&lt;00:00,  2.25it/s]"
          }
        },
        "9c3f387d895f4b06894b844a837dcb08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "008cded9607d4dc797e01ad2f7ad5e95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c4b402ae27d49bca141c34cd738d1f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0be482d975fa4cca92af125f7a6c441e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8bbe349b1e84923a6ab71c57c702f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b174347bf9fc40d89bc07bbcd7d86864": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5de433240de4f7d9f79c62c3ddd644e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install prophet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIqJVWWUD_x3",
        "outputId": "0cf5b779-d77b-4d7e-9f62-22a73d447d40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: prophet in /usr/local/lib/python3.11/dist-packages (1.1.6)\n",
            "Requirement already satisfied: cmdstanpy>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from prophet) (1.2.5)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.11/dist-packages (from prophet) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from prophet) (3.10.0)\n",
            "Requirement already satisfied: pandas>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from prophet) (2.2.2)\n",
            "Requirement already satisfied: holidays<1,>=0.25 in /usr/local/lib/python3.11/dist-packages (from prophet) (0.68)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.11/dist-packages (from prophet) (4.67.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from prophet) (6.5.2)\n",
            "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from cmdstanpy>=1.0.4->prophet) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from holidays<1,>=0.25->prophet) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->prophet) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->prophet) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->prophet) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->prophet) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->prophet) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->prophet) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->prophet) (3.2.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.4->prophet) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.4->prophet) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->holidays<1,>=0.25->prophet) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bX2lIKzT_lxb",
        "outputId": "b71ac0cd-52b4-42af-ae2f-efbf348154c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-2.20.3-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting mlflow-skinny==2.20.3 (from mlflow)\n",
            "  Downloading mlflow_skinny-2.20.3-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.5)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.26.4)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.13.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.38)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.20.3->mlflow)\n",
            "  Downloading databricks_sdk-0.45.0-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (8.6.1)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (1.16.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (1.16.0)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (24.2)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (4.25.6)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (2.10.6)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (4.12.2)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (2.38.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.20.3->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.20.3->mlflow) (3.21.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow) (1.2.18)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow) (75.1.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow) (0.37b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.20.3->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.20.3->mlflow) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.3->mlflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.3->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.3->mlflow) (2025.1.31)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow) (1.17.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.20.3->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (0.6.1)\n",
            "Downloading mlflow-2.20.3-py3-none-any.whl (28.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.4/28.4 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-2.20.3-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.45.0-py3-none-any.whl (672 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m672.8/672.8 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, gunicorn, graphql-core, graphql-relay, docker, alembic, graphene, databricks-sdk, mlflow-skinny, mlflow\n",
            "Successfully installed Mako-1.3.9 alembic-1.15.1 databricks-sdk-0.45.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.20.3 mlflow-skinny-2.20.3\n"
          ]
        }
      ],
      "source": [
        "pip install mlflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from prophet import Prophet\n",
        "import warnings\n",
        "import pickle\n",
        "import os\n",
        "import mlflow\n",
        "from mlflow.models.signature import infer_signature\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Set up MLflow tracking\n",
        "mlflow.set_tracking_uri(\"file:///path/to/your/mlruns\")  # Update this path to your mlruns folder\n",
        "mlflow.set_experiment(\"Prophet_Demand_Forecasting\")  # Set your experiment name\n",
        "\n",
        "def calculate_metrics(actual, predicted):\n",
        "    \"\"\"Calculate error metrics between actual and predicted values.\"\"\"\n",
        "    actual_arr = np.array(actual)\n",
        "    pred_arr = np.array(predicted)\n",
        "\n",
        "    mae = mean_absolute_error(actual_arr, pred_arr)\n",
        "    mse = mean_squared_error(actual_arr, pred_arr)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(actual_arr, pred_arr)\n",
        "    mape = np.mean(np.abs((actual_arr - pred_arr) / actual_arr)) * 100 if np.all(actual_arr != 0) else np.nan\n",
        "\n",
        "    return mae, mse, rmse, r2, mape\n",
        "\n",
        "def save_model_pickle(model, file_path):\n",
        "    \"\"\"Save model as pickle file.\"\"\"\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "    return file_path\n",
        "\n",
        "def load_model_pickle(file_path):\n",
        "    \"\"\"Load model from pickle file.\"\"\"\n",
        "    with open(file_path, 'rb') as f:\n",
        "        model = pickle.load(f)\n",
        "    return model\n",
        "\n",
        "def train_prophet_model(csv_path, target_column=\"Total Quantity\", epochs=5, save_dir=\"models\"):\n",
        "    \"\"\"\n",
        "    Train a Prophet time series model with MLflow tracking.\n",
        "\n",
        "    Args:\n",
        "        csv_path: Path to CSV file containing time series data\n",
        "        target_column: Column name for the target variable\n",
        "        epochs: Number of days to predict and evaluate\n",
        "        save_dir: Directory to save model files\n",
        "\n",
        "    Returns:\n",
        "        model: Trained Prophet model\n",
        "        rmse: Root Mean Squared Error of the model\n",
        "    \"\"\"\n",
        "    # Create save directory if it doesn't exist\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # Start MLflow run\n",
        "    with mlflow.start_run(nested=True) as run:\n",
        "        run_id = run.info.run_id\n",
        "        print(f\"MLflow Run ID: {run_id}\")\n",
        "\n",
        "        # Log parameters\n",
        "        mlflow.log_param(\"target_column\", target_column)\n",
        "        mlflow.log_param(\"epochs\", epochs)\n",
        "        mlflow.log_param(\"csv_file\", os.path.basename(csv_path))\n",
        "\n",
        "        # Load data\n",
        "        df = pd.read_csv(csv_path)\n",
        "\n",
        "        # Validate required columns\n",
        "        if 'Date' not in df.columns or target_column not in df.columns:\n",
        "            raise ValueError(f\"The CSV must contain 'Date' and '{target_column}' columns.\")\n",
        "\n",
        "        # Log data info\n",
        "        mlflow.log_param(\"data_rows\", len(df))\n",
        "        mlflow.log_param(\"date_range\", f\"{df['Date'].min()} to {df['Date'].max()}\")\n",
        "\n",
        "        # Process dates and handle duplicates\n",
        "        df['Date'] = pd.to_datetime(df['Date'])\n",
        "        if df['Date'].duplicated().any():\n",
        "            print(\"Warning: Duplicate dates found. Aggregating by mean.\")\n",
        "            mlflow.log_param(\"duplicate_dates_found\", True)\n",
        "            df = df.groupby('Date', as_index=False).agg({target_column: 'mean'})\n",
        "\n",
        "        # Sort by date\n",
        "        df = df.sort_values('Date')\n",
        "\n",
        "        # Prepare data for Prophet\n",
        "        prophet_df = df[['Date', target_column]].rename(columns={'Date': 'ds', target_column: 'y'})\n",
        "\n",
        "        # Add additional regressors (features)\n",
        "        additional_features = ['is_weekend', 'day_of_month', 'day_of_year', 'month', 'week_of_year', 'lag_1', 'lag_7', 'rolling_mean_7']\n",
        "        used_features = []\n",
        "        for feature in additional_features:\n",
        "            if feature in df.columns:\n",
        "                prophet_df[feature] = df[feature]\n",
        "                used_features.append(feature)\n",
        "\n",
        "        mlflow.log_param(\"additional_features\", used_features)\n",
        "\n",
        "        # Drop rows with missing values\n",
        "        original_rows = len(prophet_df)\n",
        "        prophet_df = prophet_df.dropna()\n",
        "        dropped_rows = original_rows - len(prophet_df)\n",
        "        mlflow.log_param(\"dropped_rows\", dropped_rows)\n",
        "\n",
        "        # Split into train/test sets\n",
        "        train_size = len(prophet_df) - epochs\n",
        "        if train_size <= 0:\n",
        "            mlflow.log_param(\"training_failed\", \"insufficient_data\")\n",
        "            return None\n",
        "\n",
        "        train = prophet_df.iloc[:train_size]\n",
        "        test = prophet_df.iloc[train_size:]\n",
        "\n",
        "        mlflow.log_param(\"train_size\", len(train))\n",
        "        mlflow.log_param(\"test_size\", len(test))\n",
        "\n",
        "        # Set initial hyperparameters\n",
        "        prophet_params = {\n",
        "            'changepoint_prior_scale': 0.05,\n",
        "            'seasonality_prior_scale': 10,\n",
        "            'holidays_prior_scale': 10,\n",
        "            'seasonality_mode': 'multiplicative',\n",
        "            'interval_width': 0.95,\n",
        "            'daily_seasonality': False,\n",
        "            'weekly_seasonality': True,\n",
        "            'yearly_seasonality': True,\n",
        "        }\n",
        "\n",
        "        # Log initial hyperparameters\n",
        "        for param, value in prophet_params.items():\n",
        "            mlflow.log_param(f\"initial_{param}\", value)\n",
        "\n",
        "        # Train Prophet model\n",
        "        model = Prophet(**prophet_params)\n",
        "\n",
        "        # Add additional regressors\n",
        "        for feature in used_features:\n",
        "            model.add_regressor(feature)\n",
        "\n",
        "        # Fit model\n",
        "        model.fit(train)\n",
        "\n",
        "        # Create future dataframe for prediction\n",
        "        future = model.make_future_dataframe(periods=epochs, freq='D')\n",
        "\n",
        "        # Add additional regressors to the future dataframe\n",
        "        for feature in used_features:\n",
        "            future[feature] = np.concatenate([train[feature].values, test[feature].values])\n",
        "\n",
        "        # Predict\n",
        "        forecast = model.predict(future)\n",
        "\n",
        "        # Extract predictions for test period\n",
        "        prophet_predictions = forecast.iloc[-epochs:]['yhat'].values\n",
        "\n",
        "        # Calculate metrics\n",
        "        mae, mse, rmse, r2, mape = calculate_metrics(test['y'].values, prophet_predictions)\n",
        "\n",
        "        # Log initial metrics\n",
        "        mlflow.log_metric(\"initial_mae\", mae)\n",
        "        mlflow.log_metric(\"initial_mse\", mse)\n",
        "        mlflow.log_metric(\"initial_rmse\", rmse)\n",
        "        mlflow.log_metric(\"initial_r2\", r2)\n",
        "        if not np.isnan(mape):\n",
        "            mlflow.log_metric(\"initial_mape\", mape)\n",
        "\n",
        "        # Hyperparameter tuning if RMSE is high\n",
        "        best_params = prophet_params.copy()\n",
        "        if rmse > 20:\n",
        "            mlflow.log_param(\"hyperparameter_tuning\", True)\n",
        "            param_grid = {\n",
        "                'changepoint_prior_scale': [0.001, 0.01, 0.1, 0.5],\n",
        "                'seasonality_prior_scale': [0.01, 0.1, 1.0, 10.0],\n",
        "            }\n",
        "\n",
        "            mlflow.log_param(\"tuning_grid\", param_grid)\n",
        "\n",
        "            best_rmse = rmse\n",
        "            best_model = model\n",
        "\n",
        "            for cp_scale in param_grid['changepoint_prior_scale']:\n",
        "                for s_scale in param_grid['seasonality_prior_scale']:\n",
        "                    try:\n",
        "                        with mlflow.start_run(nested=True) as child_run:\n",
        "                            trial_params = {\n",
        "                                'changepoint_prior_scale': cp_scale,\n",
        "                                'seasonality_prior_scale': s_scale,\n",
        "                                'seasonality_mode': 'multiplicative',\n",
        "                                'interval_width': 0.95\n",
        "                            }\n",
        "\n",
        "                            # Log trial parameters\n",
        "                            for param, value in trial_params.items():\n",
        "                                mlflow.log_param(param, value)\n",
        "\n",
        "                            m = Prophet(**trial_params)\n",
        "\n",
        "                            # Add additional regressors\n",
        "                            for feature in used_features:\n",
        "                                m.add_regressor(feature)\n",
        "\n",
        "                            if len(train) >= 30:\n",
        "                                m.add_seasonality(name='monthly', period=30.5, fourier_order=5)\n",
        "                                mlflow.log_param(\"added_monthly_seasonality\", True)\n",
        "\n",
        "                            m.fit(train)\n",
        "                            f = m.predict(future)\n",
        "\n",
        "                            preds = f.iloc[-epochs:]['yhat'].values\n",
        "                            trial_mae, trial_mse, trial_rmse, trial_r2, trial_mape = calculate_metrics(test['y'].values, preds)\n",
        "\n",
        "                            # Log trial metrics\n",
        "                            mlflow.log_metric(\"mae\", trial_mae)\n",
        "                            mlflow.log_metric(\"mse\", trial_mse)\n",
        "                            mlflow.log_metric(\"rmse\", trial_rmse)\n",
        "                            mlflow.log_metric(\"r2\", trial_r2)\n",
        "                            if not np.isnan(trial_mape):\n",
        "                                mlflow.log_metric(\"mape\", trial_mape)\n",
        "\n",
        "                            if trial_rmse < best_rmse:\n",
        "                                best_rmse = trial_rmse\n",
        "                                best_model = m\n",
        "                                prophet_predictions = preds\n",
        "                                best_params = trial_params.copy()\n",
        "\n",
        "                                # Save best checkpoint inside loop\n",
        "                                checkpoint_path = os.path.join(save_dir, f\"prophet_checkpoint_{child_run.info.run_id}.pkl\")\n",
        "                                save_model_pickle(m, checkpoint_path)\n",
        "                                mlflow.log_artifact(checkpoint_path)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Warning: Trial with cp_scale={cp_scale}, s_scale={s_scale} failed. Error: {e}\")\n",
        "                        mlflow.log_param(\"failed_trial\", f\"cp={cp_scale}, s={s_scale}\")\n",
        "\n",
        "            if best_model and best_rmse < rmse:\n",
        "                model = best_model\n",
        "                mae, mse, rmse, r2, mape = calculate_metrics(test['y'].values, prophet_predictions)\n",
        "\n",
        "                # Log best parameters\n",
        "                for param, value in best_params.items():\n",
        "                    mlflow.log_param(f\"best_{param}\", value)\n",
        "\n",
        "                mlflow.log_metric(\"best_mae\", mae)\n",
        "                mlflow.log_metric(\"best_mse\", mse)\n",
        "                mlflow.log_metric(\"best_rmse\", rmse)\n",
        "                mlflow.log_metric(\"best_r2\", r2)\n",
        "                if not np.isnan(mape):\n",
        "                    mlflow.log_metric(\"best_mape\", mape)\n",
        "\n",
        "        # Post-processing with Gradient Boosting\n",
        "        final_predictions = prophet_predictions\n",
        "        used_postprocessing = False\n",
        "\n",
        "        if rmse > 20:\n",
        "            try:\n",
        "                from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "                mlflow.log_param(\"attempted_postprocessing\", True)\n",
        "\n",
        "                required_columns = ['yhat', 'trend', 'yhat_lower', 'yhat_upper']\n",
        "                if all(col in forecast.columns for col in required_columns):\n",
        "                    forecast_features = forecast.iloc[-epochs-30:-epochs][required_columns]\n",
        "                    forecast_features['actual_y'] = prophet_df.iloc[train_size-30:train_size]['y'].values\n",
        "\n",
        "                    X_train = forecast_features.drop(['actual_y'], axis=1)\n",
        "                    y_train = forecast_features['actual_y']\n",
        "\n",
        "                    correction_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1)\n",
        "                    correction_model.fit(X_train, y_train)\n",
        "\n",
        "                    test_features = forecast.iloc[-epochs:][required_columns]\n",
        "                    corrected_predictions = correction_model.predict(test_features)\n",
        "\n",
        "                    corrected_mae, corrected_mse, corrected_rmse, corrected_r2, corrected_mape = calculate_metrics(\n",
        "                        test['y'].values, corrected_predictions)\n",
        "\n",
        "                    # Log post-processing metrics\n",
        "                    mlflow.log_metric(\"pp_mae\", corrected_mae)\n",
        "                    mlflow.log_metric(\"pp_mse\", corrected_mse)\n",
        "                    mlflow.log_metric(\"pp_rmse\", corrected_rmse)\n",
        "                    mlflow.log_metric(\"pp_r2\", corrected_r2)\n",
        "                    if not np.isnan(corrected_mape):\n",
        "                        mlflow.log_metric(\"pp_mape\", corrected_mape)\n",
        "\n",
        "                    if corrected_rmse < rmse:\n",
        "                        mae, mse, rmse, r2, mape = corrected_mae, corrected_mse, corrected_rmse, corrected_r2, corrected_mape\n",
        "                        final_predictions = corrected_predictions\n",
        "                        used_postprocessing = True\n",
        "\n",
        "                        # Save correction model\n",
        "                        correction_model_path = os.path.join(save_dir, \"correction_model.pkl\")\n",
        "                        save_model_pickle(correction_model, correction_model_path)\n",
        "                        mlflow.log_artifact(correction_model_path)\n",
        "                        mlflow.log_param(\"used_postprocessing\", True)\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Post-processing failed. Error: {e}\")\n",
        "                mlflow.log_param(\"postprocessing_error\", str(e))\n",
        "\n",
        "        # Create performance metrics table\n",
        "        metrics = {\n",
        "            'Metric': ['MAE', 'MSE', 'RMSE', 'R²', 'MAPE (%)'],\n",
        "            'Value': [mae, mse, rmse, r2, mape]\n",
        "        }\n",
        "        metrics_df = pd.DataFrame(metrics)\n",
        "\n",
        "        # Create comparison table\n",
        "        comparison = pd.DataFrame({\n",
        "            'Date': test['ds'].values,\n",
        "            'Actual': test['y'].values,\n",
        "            'Predicted': final_predictions,\n",
        "            'Error': np.abs(test['y'].values - final_predictions),\n",
        "            'Percentage Error': np.abs((test['y'].values - final_predictions) / test['y'].values) * 100\n",
        "                                if np.all(test['y'].values != 0) else np.nan\n",
        "        })\n",
        "\n",
        "        # Save metrics and comparison tables as CSV\n",
        "        metrics_path = os.path.join(save_dir, \"metrics.csv\")\n",
        "        comparison_path = os.path.join(save_dir, \"predictions.csv\")\n",
        "        metrics_df.to_csv(metrics_path, index=False)\n",
        "        comparison.to_csv(comparison_path, index=False)\n",
        "\n",
        "        # Log as MLflow artifacts\n",
        "        mlflow.log_artifact(metrics_path)\n",
        "        mlflow.log_artifact(comparison_path)\n",
        "\n",
        "        # Print results\n",
        "        print(\"\\n===== PERFORMANCE METRICS =====\")\n",
        "        print(metrics_df.to_string(index=False))\n",
        "\n",
        "        print(\"\\n===== PREDICTION RESULTS =====\")\n",
        "        print(comparison.to_string(index=False))\n",
        "\n",
        "        # Save final model\n",
        "        model_path = os.path.join(save_dir, f\"prophet_model_{run_id}.pkl\")\n",
        "        save_model_pickle(model, model_path)\n",
        "\n",
        "        # Log final metrics\n",
        "        mlflow.log_metric(\"final_mae\", mae)\n",
        "        mlflow.log_metric(\"final_mse\", mse)\n",
        "        mlflow.log_metric(\"final_rmse\", rmse)\n",
        "        mlflow.log_metric(\"final_r2\", r2)\n",
        "        if not np.isnan(mape):\n",
        "            mlflow.log_metric(\"final_mape\", mape)\n",
        "\n",
        "        # Create a sample input for model signature\n",
        "        sample_input = pd.DataFrame({'ds': [pd.Timestamp.now()]})\n",
        "        for feature in used_features:\n",
        "            sample_input[feature] = [0.0]  # Sample value\n",
        "\n",
        "        # Create a sample output for model signature\n",
        "        sample_output = pd.DataFrame({'yhat': [0.0], 'trend': [0.0], 'yhat_lower': [0.0], 'yhat_upper': [0.0]})\n",
        "\n",
        "        # Infer model signature\n",
        "        signature = infer_signature(sample_input, sample_output)\n",
        "\n",
        "        # Log the model as an MLflow artifact\n",
        "        mlflow.pyfunc.log_model(\n",
        "            artifact_path=\"prophet_model\",\n",
        "            python_model=ProphetWrapper(model, used_features),\n",
        "            artifacts={\"prophet_model\": model_path},\n",
        "            signature=signature\n",
        "        )\n",
        "\n",
        "        # Log the pickle file separately\n",
        "        mlflow.log_artifact(model_path)\n",
        "\n",
        "        print(f\"Model saved to {model_path}\")\n",
        "        print(f\"MLflow run ID: {run_id}\")\n",
        "\n",
        "        return model, rmse\n",
        "\n",
        "class ProphetWrapper(mlflow.pyfunc.PythonModel):\n",
        "    \"\"\"Wrapper class for Prophet model to use with MLflow.\"\"\"\n",
        "\n",
        "    def __init__(self, model, features):\n",
        "        self.model = model\n",
        "        self.features = features\n",
        "\n",
        "    def load_context(self, context):\n",
        "        \"\"\"Load model from the artifacts.\"\"\"\n",
        "        import pickle\n",
        "\n",
        "        with open(context.artifacts[\"prophet_model\"], \"rb\") as f:\n",
        "            self.model = pickle.load(f)\n",
        "\n",
        "    def predict(self, context, model_input):\n",
        "        \"\"\"Make predictions with the model.\"\"\"\n",
        "        future = self.model.make_future_dataframe(periods=len(model_input), freq='D')\n",
        "\n",
        "        # Add regressor values if available\n",
        "        for feature in self.features:\n",
        "            if feature in model_input.columns:\n",
        "                future[feature] = model_input[feature].values\n",
        "\n",
        "        # Make predictions\n",
        "        forecast = self.model.predict(future)\n",
        "        return forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
        "\n",
        "def load_and_predict(run_id, prediction_dates, csv_path=None, features_data=None):\n",
        "    \"\"\"\n",
        "    Load a saved Prophet model from MLflow and make predictions.\n",
        "\n",
        "    Args:\n",
        "        run_id: MLflow run ID\n",
        "        prediction_dates: List or array of dates to predict for\n",
        "        csv_path: Optional path to CSV file with feature data\n",
        "        features_data: Optional DataFrame with feature data\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with predictions\n",
        "    \"\"\"\n",
        "    # Load the model from MLflow\n",
        "    model_uri = f\"runs:/{run_id}/prophet_model\"\n",
        "    loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
        "\n",
        "    # Prepare input dataframe\n",
        "    input_df = pd.DataFrame({'ds': pd.to_datetime(prediction_dates)})\n",
        "\n",
        "    # Add features if provided\n",
        "    if features_data is not None:\n",
        "        for col in features_data.columns:\n",
        "            if col != 'ds' and col != 'Date':\n",
        "                input_df[col] = features_data[col].values\n",
        "    elif csv_path is not None:\n",
        "        df = pd.read_csv(csv_path)\n",
        "        df['Date'] = pd.to_datetime(df['Date'])\n",
        "        df = df[df['Date'].isin(prediction_dates)]\n",
        "\n",
        "        for col in df.columns:\n",
        "            if col != 'Date' and col != 'ds':\n",
        "                input_df[col] = df[col].values\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = loaded_model.predict(input_df)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage\n",
        "    csv_path = \"ML.csv\"  # Replace with your CSV file path\n",
        "    save_dir = \"prophet_models\"\n",
        "\n",
        "    model, rmse = train_prophet_model(csv_path, target_column=\"Total Quantity\", epochs=5, save_dir=save_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641,
          "referenced_widgets": [
            "5f2f0b60ad6e4390824a5de1d711a1a2",
            "d8ef1bd53b64418fbc608be7cdb69ab7",
            "166915f6a5f44ab2be6895a7db4c213c",
            "e8dc03ba59bb44348fb4006e8fd05690",
            "5090ffb6d9b9444a96a13c1ff2c28d39",
            "804bf3ed5ba644c09821bc777b841177",
            "1cce153c421c4348b986ab43daec9288",
            "ec24827ee60e4e469ab54e18eb59a8ef",
            "6f9782c73d284ee1a9e6b74c33d2cabd",
            "3ee49c86ec794f1296016e5d3a712765",
            "3420a02b032a41e9a137b344f7a54421"
          ]
        },
        "id": "T-0N7DM7_nhB",
        "outputId": "0b4af949-c20a-46cd-c16d-071ee6b25117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/mlflow/pyfunc/utils/data_validation.py:168: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
            "  color_warning(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLflow Run ID: 828f10ca4f8f4e00bbf5dccc433ef4e5\n",
            "Warning: Duplicate dates found. Aggregating by mean.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpk3w0xnsv/jh32_27d.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpk3w0xnsv/3jedyr2u.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.11/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=87762', 'data', 'file=/tmp/tmpk3w0xnsv/jh32_27d.json', 'init=/tmp/tmpk3w0xnsv/3jedyr2u.json', 'output', 'file=/tmp/tmpk3w0xnsv/prophet_modelq_imqrl0/prophet_model-20250307190543.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "19:05:43 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "19:05:43 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== PERFORMANCE METRICS =====\n",
            "  Metric    Value\n",
            "     MAE 1.610065\n",
            "     MSE 2.985238\n",
            "    RMSE 1.727784\n",
            "      R² 0.838832\n",
            "MAPE (%) 1.120920\n",
            "\n",
            "===== PREDICTION RESULTS =====\n",
            "      Date  Actual  Predicted    Error  Percentage Error\n",
            "2024-12-27 148.500 150.364067 1.864067          1.255264\n",
            "2024-12-28 138.250 139.566849 1.316849          0.952513\n",
            "2024-12-29 142.750 143.424374 0.674374          0.472416\n",
            "2024-12-30 138.125 139.741157 1.616157          1.170068\n",
            "2024-12-31 147.000 144.421123 2.578877          1.754338\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f2f0b60ad6e4390824a5de1d711a1a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to prophet_models/prophet_model_828f10ca4f8f4e00bbf5dccc433ef4e5.pkl\n",
            "MLflow run ID: 828f10ca4f8f4e00bbf5dccc433ef4e5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from prophet import Prophet\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from tqdm.notebook import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load the dataset (replace with your actual data loading)\n",
        "df = pd.read_csv('ML.csv')\n",
        "\n",
        "# For demonstration, create sample data similar to your description\n",
        "date_range = pd.date_range(start='2023-01-01', end='2024-02-29', freq='D')\n",
        "np.random.seed(42)\n",
        "\n",
        "# Use the specific product names you provided\n",
        "products = ['beef', 'corn', 'milk', 'sugar', 'wheat', 'chocolate', 'coffee', 'soybeans']\n",
        "data = []\n",
        "\n",
        "for product in products:\n",
        "    for date in date_range:\n",
        "        # Base quantity with some seasonality\n",
        "        base_qty = 100 + 20 * np.sin(date.dayofyear * 2 * np.pi / 365)\n",
        "\n",
        "        # Product-specific patterns (simplified)\n",
        "        if product == 'milk':\n",
        "            day_effect = 15 if date.dayofweek < 5 else -10\n",
        "        elif product == 'chocolate':\n",
        "            month_effect = 30 if date.month in [1, 2, 12] else 0\n",
        "            day_effect = 50 if date.month == 2 and date.day == 14 else 0  # Valentine's Day\n",
        "        elif product == 'coffee':\n",
        "            day_effect = 5 if date.month in [11, 12, 1, 2] else 0\n",
        "        elif product in ['corn', 'wheat', 'soybeans']:\n",
        "            day_effect = -20 if date.month in [9, 10] else 10\n",
        "        elif product == 'sugar':\n",
        "            day_effect = 25 if date.month in [11, 12] else 0\n",
        "        else:  # beef\n",
        "            day_effect = 20 if date.dayofweek >= 5 else 0\n",
        "\n",
        "        # Monthly pattern (simplified)\n",
        "        month_effect = date.month * 3\n",
        "\n",
        "        # Random noise\n",
        "        noise = np.random.normal(0, 10)\n",
        "\n",
        "        quantity = max(1, int(base_qty + day_effect + month_effect + noise))\n",
        "\n",
        "        # Calculate derived features (simplified)\n",
        "        data.append({\n",
        "            'Date': date,\n",
        "            'Product_Name': product,\n",
        "            'Total_Quantity': quantity,\n",
        "            'day_of_week': date.dayofweek,\n",
        "            'month': date.month,\n",
        "        })\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate lag features more efficiently using pandas\n",
        "def add_lag_features(df, product_name, lag_days=[1, 7]):\n",
        "    product_df = df[df['Product_Name'] == product_name].copy()\n",
        "    product_df = product_df.sort_values('Date')\n",
        "\n",
        "    # Add lag features\n",
        "    for lag in lag_days:\n",
        "        product_df[f'lag_{lag}'] = product_df['Total_Quantity'].shift(lag)\n",
        "\n",
        "    # Add rolling mean (more efficient)\n",
        "    product_df['rolling_mean_7'] = product_df['Total_Quantity'].rolling(window=7).mean()\n",
        "\n",
        "    return product_df.dropna()\n",
        "\n",
        "# Function to train Prophet model (simplified)\n",
        "def train_prophet_model(product_data, product_name, use_hyperparams=False):\n",
        "    # Prepare data for Prophet\n",
        "    prophet_data = product_data[['Date', 'Total_Quantity']].rename(\n",
        "        columns={'Date': 'ds', 'Total_Quantity': 'y'}\n",
        "    )\n",
        "\n",
        "    # Add regressors if they exist\n",
        "    regressors = []\n",
        "    for col in ['lag_1', 'lag_7', 'rolling_mean_7']:\n",
        "        if col in product_data.columns:\n",
        "            prophet_data[col] = product_data[col]\n",
        "            regressors.append(col)\n",
        "\n",
        "    # Split data into train and test (last 30 days)\n",
        "    train_data = prophet_data.iloc[:-30]\n",
        "    test_data = prophet_data.iloc[-30:]\n",
        "\n",
        "    # Best parameters (preset to avoid tuning)\n",
        "    best_params = {\n",
        "        'yearly_seasonality': True,\n",
        "        'weekly_seasonality': True,\n",
        "        'daily_seasonality': False,\n",
        "        'seasonality_mode': 'multiplicative',\n",
        "        'changepoint_prior_scale': 0.1,\n",
        "        'seasonality_prior_scale': 1.0\n",
        "    }\n",
        "\n",
        "    # Train with best parameters\n",
        "    model = Prophet(**best_params)\n",
        "\n",
        "    # Add regressors\n",
        "    for regressor in regressors:\n",
        "        model.add_regressor(regressor)\n",
        "\n",
        "    # Fit model\n",
        "    model.fit(train_data)\n",
        "\n",
        "    # Make predictions on test data\n",
        "    forecast = model.predict(test_data)\n",
        "\n",
        "    # Calculate metrics\n",
        "    mae = mean_absolute_error(test_data['y'], forecast['yhat'])\n",
        "    rmse = np.sqrt(mean_squared_error(test_data['y'], forecast['yhat']))\n",
        "    r2 = r2_score(test_data['y'], forecast['yhat'])\n",
        "\n",
        "    # Generate future forecast (next 30 days)\n",
        "    last_date = prophet_data['ds'].max()\n",
        "    future_dates = pd.date_range(\n",
        "        start=last_date + pd.Timedelta(days=1),\n",
        "        periods=30\n",
        "    )\n",
        "    future = pd.DataFrame({'ds': future_dates})\n",
        "\n",
        "    # Simplified forecast - Handle regressor values more efficiently\n",
        "    if regressors:\n",
        "        # Use simpler approximation for regressors\n",
        "        for regressor in regressors:\n",
        "            if regressor == 'lag_1':\n",
        "                # Set lag_1 to the average of last 7 days for simplicity\n",
        "                future[regressor] = prophet_data['y'].tail(7).mean()\n",
        "            elif regressor == 'lag_7':\n",
        "                # Set lag_7 to the average of last 14 days for simplicity\n",
        "                future[regressor] = prophet_data['y'].tail(14).mean()\n",
        "            elif regressor == 'rolling_mean_7':\n",
        "                # Set rolling_mean to the average of last 14 days for simplicity\n",
        "                future[regressor] = prophet_data['y'].tail(14).mean()\n",
        "\n",
        "    # Make prediction for the future\n",
        "    future_forecast = model.predict(future)\n",
        "\n",
        "    return model, future_forecast, mae, rmse, r2\n",
        "\n",
        "# Container for results\n",
        "models = {}\n",
        "forecasts = {}\n",
        "metrics = {}\n",
        "\n",
        "# Process products using more efficient approach\n",
        "for product in tqdm(products, desc=\"Processing products\"):\n",
        "    # Add lag features for this product only\n",
        "    product_data = add_lag_features(df, product)\n",
        "\n",
        "    if len(product_data) < 30:\n",
        "        continue\n",
        "\n",
        "    # Train model without expensive hyperparameter tuning\n",
        "    model, forecast, mae, rmse, r2 = train_prophet_model(\n",
        "        product_data,\n",
        "        product,\n",
        "        use_hyperparams=False  # Skip hyperparameter tuning\n",
        "    )\n",
        "\n",
        "    if model is not None:\n",
        "        models[product] = model\n",
        "        forecasts[product] = forecast\n",
        "        metrics[product] = {'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
        "\n",
        "if metrics:\n",
        "    metrics_df = pd.DataFrame.from_dict(metrics, orient='index')\n",
        "    print(\"\\nModel Performance Metrics:\")\n",
        "    print(metrics_df)\n",
        "    print(f\"Average MAE: {metrics_df['MAE'].mean():.2f}\")\n",
        "    print(f\"Average RMSE: {metrics_df['RMSE'].mean():.2f}\")\n",
        "    print(f\"Average R²: {metrics_df['R2'].mean():.4f}\")\n",
        "\n",
        "# Create a consolidated forecast dataframe\n",
        "consolidated_forecast = pd.DataFrame()\n",
        "\n",
        "for product in products:\n",
        "    if product in forecasts:\n",
        "        product_forecast = forecasts[product]\n",
        "\n",
        "        # Create a dataframe with forecast info\n",
        "        temp_df = pd.DataFrame({\n",
        "            'Date': product_forecast['ds'],\n",
        "            'Product_Name': product,\n",
        "            'Forecasted_Quantity': product_forecast['yhat'],\n",
        "            'Lower_Bound': product_forecast['yhat_lower'],\n",
        "            'Upper_Bound': product_forecast['yhat_upper']\n",
        "        })\n",
        "\n",
        "        consolidated_forecast = pd.concat([consolidated_forecast, temp_df])\n",
        "\n",
        "if not consolidated_forecast.empty:\n",
        "    # Sort by date and product\n",
        "    consolidated_forecast = consolidated_forecast.sort_values(['Date', 'Product_Name'])\n",
        "\n",
        "    # Save consolidated forecast\n",
        "    consolidated_forecast.to_csv('all_products_forecast.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cb3fe9f606794b9bba1317978f565613",
            "e0d099a5ac5a4982ba909ab6650fa1cc",
            "8d00ec2573794614808411ed4522b983",
            "096ba20fca974672b7c11008cdc2f1a0",
            "9c3f387d895f4b06894b844a837dcb08",
            "008cded9607d4dc797e01ad2f7ad5e95",
            "8c4b402ae27d49bca141c34cd738d1f7",
            "0be482d975fa4cca92af125f7a6c441e",
            "c8bbe349b1e84923a6ab71c57c702f39",
            "b174347bf9fc40d89bc07bbcd7d86864",
            "c5de433240de4f7d9f79c62c3ddd644e"
          ]
        },
        "id": "3evz9SYl1s7E",
        "outputId": "5e9fdbaf-eb78-4860-ed20-d812172f496d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing products:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb3fe9f606794b9bba1317978f565613"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpv63jhtme/1qlccqbx.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpv63jhtme/wkr70jyd.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.11/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=85664', 'data', 'file=/tmp/tmpv63jhtme/1qlccqbx.json', 'init=/tmp/tmpv63jhtme/wkr70jyd.json', 'output', 'file=/tmp/tmpv63jhtme/prophet_model2gpy5cfm/prophet_model-20250308224100.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:41:00 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:41:00 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpv63jhtme/jehjfkf4.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpv63jhtme/j73a7e1q.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.11/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=30687', 'data', 'file=/tmp/tmpv63jhtme/jehjfkf4.json', 'init=/tmp/tmpv63jhtme/j73a7e1q.json', 'output', 'file=/tmp/tmpv63jhtme/prophet_modelu0x12n_u/prophet_model-20250308224101.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:41:01 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:41:01 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpv63jhtme/h4u3n_jg.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpv63jhtme/xeq1e7um.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.11/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=85480', 'data', 'file=/tmp/tmpv63jhtme/h4u3n_jg.json', 'init=/tmp/tmpv63jhtme/xeq1e7um.json', 'output', 'file=/tmp/tmpv63jhtme/prophet_model7lwr1dcm/prophet_model-20250308224101.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:41:01 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:41:01 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpv63jhtme/1awt2sqv.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpv63jhtme/fx_7snbn.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.11/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=84597', 'data', 'file=/tmp/tmpv63jhtme/1awt2sqv.json', 'init=/tmp/tmpv63jhtme/fx_7snbn.json', 'output', 'file=/tmp/tmpv63jhtme/prophet_modellfoktkxw/prophet_model-20250308224102.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:41:02 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:41:02 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpv63jhtme/kv7yjf3z.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpv63jhtme/4eklboi8.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.11/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=21835', 'data', 'file=/tmp/tmpv63jhtme/kv7yjf3z.json', 'init=/tmp/tmpv63jhtme/4eklboi8.json', 'output', 'file=/tmp/tmpv63jhtme/prophet_modelm7kxhsl4/prophet_model-20250308224103.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:41:03 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:41:03 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpv63jhtme/zbuv5i6h.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpv63jhtme/4w08o9sf.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.11/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=32484', 'data', 'file=/tmp/tmpv63jhtme/zbuv5i6h.json', 'init=/tmp/tmpv63jhtme/4w08o9sf.json', 'output', 'file=/tmp/tmpv63jhtme/prophet_model0g28uugx/prophet_model-20250308224103.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:41:03 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:41:03 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpv63jhtme/t60723fc.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpv63jhtme/41yle2f3.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.11/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=80434', 'data', 'file=/tmp/tmpv63jhtme/t60723fc.json', 'init=/tmp/tmpv63jhtme/41yle2f3.json', 'output', 'file=/tmp/tmpv63jhtme/prophet_model9ch9tczi/prophet_model-20250308224103.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:41:03 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:41:03 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpv63jhtme/b2ez5lxi.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpv63jhtme/y2in7t8e.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.11/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=30048', 'data', 'file=/tmp/tmpv63jhtme/b2ez5lxi.json', 'init=/tmp/tmpv63jhtme/y2in7t8e.json', 'output', 'file=/tmp/tmpv63jhtme/prophet_modelt7cjrsb7/prophet_model-20250308224104.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:41:04 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:41:04 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Performance Metrics:\n",
            "                MAE       RMSE        R2\n",
            "beef       6.662814   7.877375  0.715608\n",
            "corn       8.076735   9.560454  0.119259\n",
            "milk       8.964739  11.150455  0.368100\n",
            "sugar      6.995440   8.716770  0.023492\n",
            "wheat      7.112712   9.024526  0.229449\n",
            "chocolate  9.639820  13.258660  0.019285\n",
            "coffee     9.856897  12.169043  0.025923\n",
            "soybeans   8.951347  11.174621  0.110062\n",
            "Average MAE: 8.28\n",
            "Average RMSE: 10.37\n",
            "Average R²: 0.2014\n"
          ]
        }
      ]
    }
  ]
}